{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/randal_olson/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3569: RuntimeWarning: Invalid value encountered in median\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg        \tstd        \tmin   \tmax       \n",
      "0  \t500   \t5.35513e+22\t1.19308e+24\t262157\t2.6705e+25\n",
      "1  \t500   \t1.77089e+18\t1.97198e+19\t262157\t2.21361e+20\n",
      "2  \t500   \t9.29716e+18\t4.44026e+19\t262157\t2.21361e+20\n",
      "3  \t500   \t1.37244e+19\t5.33824e+19\t262157\t2.21361e+20\n",
      "4  \t500   \t1.50525e+19\t5.57267e+19\t262157\t2.21361e+20\n",
      "5  \t500   \t2.03652e+19\t6.39791e+19\t262157\t2.21361e+20\n",
      "6  \t500   \t1.9037e+19 \t6.20616e+19\t262157\t2.21361e+20\n",
      "7  \t500   \t2.21361e+19\t6.64083e+19\t261620\t2.21361e+20\n",
      "8  \t500   \t2.34643e+19\t6.81432e+19\t261620\t2.21361e+20\n",
      "9  \t500   \t2.92196e+19\t7.49286e+19\t262157\t2.21361e+20\n",
      "10 \t500   \t3.14333e+19\t7.72661e+19\t262157\t2.21361e+20\n",
      "11 \t500   \t2.56779e+19\t7.08853e+19\t262157\t2.21361e+20\n",
      "12 \t500   \t2.65633e+19\t7.19338e+19\t262157\t2.21361e+20\n",
      "13 \t500   \t2.16934e+19\t6.58138e+19\t240117\t2.21361e+20\n",
      "14 \t500   \t2.03652e+19\t6.39791e+19\t240117\t2.21361e+20\n",
      "15 \t500   \t1.85943e+19\t6.14028e+19\t240117\t2.21361e+20\n",
      "16 \t500   \t2.47924e+19\t6.98098e+19\t240117\t2.21361e+20\n",
      "17 \t500   \t2.47924e+19\t6.98098e+19\t240117\t2.21361e+20\n",
      "18 \t500   \t2.3907e+19 \t6.87061e+19\t174957\t2.21361e+20\n",
      "19 \t500   \t2.03652e+19\t6.39791e+19\t174957\t2.21361e+20\n",
      "20 \t500   \t2.56779e+19\t7.08853e+19\t174957\t2.21361e+20\n",
      "21 \t500   \t2.30215e+19\t6.75728e+19\t174957\t2.21361e+20\n",
      "22 \t500   \t1.81516e+19\t6.07336e+19\t174948\t2.21361e+20\n",
      "23 \t500   \t1.94798e+19\t6.27104e+19\t174204\t2.21361e+20\n",
      "24 \t500   \t2.16934e+19\t6.58138e+19\t174204\t2.21361e+20\n",
      "25 \t500   \t2.16934e+19\t6.58138e+19\t174204\t2.21361e+20\n",
      "26 \t500   \t2.52351e+19\t7.0351e+19 \t174204\t2.21361e+20\n",
      "27 \t500   \t2.16934e+19\t6.58138e+19\t174204\t2.21361e+20\n",
      "28 \t500   \t2.21361e+19\t6.64083e+19\t173928\t2.21361e+20\n",
      "29 \t500   \t1.9037e+19 \t6.20616e+19\t173928\t2.21361e+20\n",
      "30 \t500   \t1.77089e+19\t6.00537e+19\t173928\t2.21361e+20\n",
      "31 \t500   \t2.12506e+19\t6.5211e+19 \t173928\t2.21361e+20\n",
      "32 \t500   \t1.94798e+19\t6.27104e+19\t173928\t2.21361e+20\n",
      "33 \t500   \t1.85943e+19\t6.14028e+19\t173928\t2.21361e+20\n",
      "34 \t500   \t1.9037e+19 \t6.20616e+19\t173928\t2.21361e+20\n",
      "35 \t500   \t1.46098e+19\t5.496e+19  \t168046\t2.21361e+20\n",
      "36 \t500   \t1.77089e+19\t6.00537e+19\t168046\t2.21361e+20\n",
      "37 \t500   \t1.28389e+19\t5.17417e+19\t168046\t2.21361e+20\n",
      "38 \t500   \t1.50525e+19\t5.57267e+19\t168046\t2.21361e+20\n",
      "39 \t500   \t1.81516e+19\t6.07336e+19\t168046\t2.21361e+20\n",
      "40 \t500   \t1.5938e+19 \t5.72191e+19\t168046\t2.21361e+20\n",
      "41 \t500   \t1.46098e+19\t5.496e+19  \t167529\t2.21361e+20\n",
      "42 \t500   \t1.32817e+19\t5.25703e+19\t167529\t2.21361e+20\n",
      "43 \t500   \t1.50525e+19\t5.57267e+19\t167529\t2.21361e+20\n",
      "44 \t500   \t1.41671e+19\t5.41787e+19\t167529\t2.21361e+20\n",
      "45 \t500   \t1.50525e+19\t5.57267e+19\t167529\t2.21361e+20\n",
      "46 \t500   \t1.68234e+19\t5.86602e+19\t167529\t2.21361e+20\n",
      "47 \t500   \t1.50525e+19\t5.57267e+19\t167529\t2.21361e+20\n",
      "48 \t500   \t1.19535e+19\t5.00315e+19\t167529\t2.21361e+20\n",
      "49 \t500   \t1.46098e+19\t5.496e+19  \t167529\t2.21361e+20\n",
      "50 \t500   \t1.46098e+19\t5.496e+19  \t167529\t2.21361e+20\n",
      "\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n",
      "167529.435996 7.0 array_mean(array_div_float(array_div_float(array_div_float(x2, array_min(x1)), array_stderr(x1)), array_stderr(x2)))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import operator\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "random.seed(int(sys.argv[1]))\n",
    "np.random.seed(int(sys.argv[1]))\n",
    "\"\"\"\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "\n",
    "def selAutomaticEpsilonLexicase(individuals, k):\n",
    "    \"\"\"\n",
    "    Returns an individual that does the best on the fitness cases when considered one at a\n",
    "    time in random order. \n",
    "    https://push-language.hampshire.edu/uploads/default/original/1X/35c30e47ef6323a0a949402914453f277fb1b5b0.pdf\n",
    "    Implemented lambda_epsilon_y implementation.\n",
    "    :param individuals: A list of individuals to select from.\n",
    "    :param k: The number of individuals to select.\n",
    "    :returns: A list of selected individuals.\n",
    "    \"\"\"      \n",
    "    selected_individuals = [] \n",
    "    individual_complexities = [np.sum([type(component) == gp.Primitive for component in individual])\n",
    "                               for individual in individuals]\n",
    "    \n",
    "    for i in range(k):\n",
    "        fit_weights = individuals[0].fitness.weights\n",
    "        \n",
    "        random_individual_complexity = random.choice(individual_complexities)\n",
    "        candidates = []\n",
    "        for individual_num, individual in enumerate(individuals):\n",
    "            if individual_complexities[individual_num] <= random_individual_complexity:\n",
    "                candidates.append(individual)\n",
    "        cases = list(range(len(individuals[0].fitness.values)))\n",
    "        random.shuffle(cases)\n",
    "\n",
    "        while len(cases) > 0 and len(candidates) > 1: \n",
    "            errors_for_this_case = [x.fitness.values[cases[0]] for x in candidates]\n",
    "            median_val = np.median(errors_for_this_case)\n",
    "            median_absolute_deviation = np.median([abs(x - median_val) for x in errors_for_this_case])\n",
    "            if fit_weights[cases[0]] > 0:\n",
    "                best_val_for_case = max(errors_for_this_case) \n",
    "                min_val_to_survive = best_val_for_case - median_absolute_deviation\n",
    "                candidates = list(filter(lambda x: x.fitness.values[cases[0]] >= min_val_to_survive, candidates))\n",
    "            else:\n",
    "                best_val_for_case = min(errors_for_this_case) \n",
    "                max_val_to_survive = best_val_for_case + median_absolute_deviation\n",
    "                candidates = list(filter(lambda x: x.fitness.values[cases[0]] <= max_val_to_survive, candidates))\n",
    "            \n",
    "            cases.pop(0)\n",
    "                     \n",
    "        selected_individuals.append(random.choice(candidates))\n",
    "    \n",
    "    return selected_individuals\n",
    "\n",
    "\n",
    "num_splits = 24\n",
    "\n",
    "#def runGA():\n",
    "# Generate the distributions to be used in the GP optimization process\n",
    "\n",
    "# Index by: [sample number (0-29)]\n",
    "sig_diff_samples_0v10 = np.random.normal(loc=0, scale=3, size=(30, 500))\n",
    "sig_diff_samples_10v0 = np.random.normal(loc=10, scale=5, size=(30, 500))\n",
    "\n",
    "sig_diff_samples_0v10_same_std = np.random.normal(loc=0, scale=3, size=(30, 500))\n",
    "sig_diff_samples_10v0_same_std = np.random.normal(loc=100, scale=3, size=(30, 500))\n",
    "\n",
    "sig_diff_samples_0v100 = np.random.normal(loc=0, scale=3, size=(30, 500))\n",
    "sig_diff_samples_100v0 = np.random.normal(loc=100, scale=5, size=(30, 500))\n",
    "\n",
    "sig_diff_samples_0v100_same_std = np.random.normal(loc=0, scale=30, size=(30, 500))\n",
    "sig_diff_samples_100v0_same_std = np.random.normal(loc=100, scale=30, size=(30, 500))\n",
    "\n",
    "sig_diff_samples_0v1000 = np.random.normal(loc=0, scale=3, size=(30, 500))\n",
    "sig_diff_samples_1000v0 = np.random.normal(loc=1000, scale=5, size=(30, 500))\n",
    "\n",
    "sig_diff_samples_0v1000_same_std = np.random.normal(loc=0, scale=300, size=(30, 500))\n",
    "sig_diff_samples_1000v0_same_std = np.random.normal(loc=1000, scale=300, size=(30, 500))\n",
    "\n",
    "# Index by: [group (0/1)][sample number (0-29)]\n",
    "both_dist = np.append(sig_diff_samples_0v10.reshape(\n",
    "                          sig_diff_samples_0v10.shape[0] * sig_diff_samples_0v10.shape[1]),\n",
    "                      sig_diff_samples_10v0.reshape(\n",
    "                          sig_diff_samples_10v0.shape[0] * sig_diff_samples_10v0.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v10 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v10 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "both_dist = np.append(sig_diff_samples_0v10_same_std.reshape(\n",
    "                          sig_diff_samples_0v10_same_std.shape[0] * sig_diff_samples_0v10_same_std.shape[1]),\n",
    "                      sig_diff_samples_10v0_same_std.reshape(\n",
    "                          sig_diff_samples_10v0_same_std.shape[0] * sig_diff_samples_10v0_same_std.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v10_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v10_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "both_dist = np.append(sig_diff_samples_0v100.reshape(\n",
    "                          sig_diff_samples_0v100.shape[0] * sig_diff_samples_0v100.shape[1]),\n",
    "                      sig_diff_samples_100v0.reshape(\n",
    "                          sig_diff_samples_100v0.shape[0] * sig_diff_samples_100v0.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v100 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v100 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "both_dist = np.append(sig_diff_samples_0v100_same_std.reshape(\n",
    "                          sig_diff_samples_0v100_same_std.shape[0] * sig_diff_samples_0v100_same_std.shape[1]),\n",
    "                      sig_diff_samples_100v0_same_std.reshape(\n",
    "                          sig_diff_samples_100v0_same_std.shape[0] * sig_diff_samples_100v0_same_std.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v100_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v100_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "both_dist = np.append(sig_diff_samples_0v1000.reshape(\n",
    "                          sig_diff_samples_0v1000.shape[0] * sig_diff_samples_0v1000.shape[1]),\n",
    "                      sig_diff_samples_1000v0.reshape(\n",
    "                          sig_diff_samples_1000v0.shape[0] * sig_diff_samples_1000v0.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v1000 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v1000 = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "both_dist = np.append(sig_diff_samples_0v1000_same_std.reshape(\n",
    "                          sig_diff_samples_0v1000_same_std.shape[0] * sig_diff_samples_0v1000_same_std.shape[1]),\n",
    "                      sig_diff_samples_1000v0_same_std.reshape(\n",
    "                          sig_diff_samples_1000v0_same_std.shape[0] * sig_diff_samples_1000v0_same_std.shape[1]))\n",
    "both_dist_mean = np.mean(both_dist)\n",
    "both_dist_sd = np.std(both_dist)\n",
    "permuted_samples_0v1000_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "null_samples_0v1000_same_std = np.random.normal(loc=both_dist_mean, scale=both_dist_sd, size=(2, 30, 500))\n",
    "\n",
    "ttest_vals = []\n",
    "\n",
    "# Sig diff sample comparisons\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v10, sig_diff_samples_10v0):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v100, sig_diff_samples_100v0):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v1000, sig_diff_samples_1000v0):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v10_same_std, sig_diff_samples_10v0_same_std):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v100_same_std, sig_diff_samples_100v0_same_std):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(sig_diff_samples_0v1000_same_std, sig_diff_samples_1000v0_same_std):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "    ttest_vals.append(ttest_ind(sample2, sample1).statistic)\n",
    "\n",
    "# Null sample comparisons\n",
    "for sample1, sample2 in zip(null_samples_0v10[0], null_samples_0v10[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(null_samples_0v100[0], null_samples_0v100[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(null_samples_0v1000[0], null_samples_0v1000[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(null_samples_0v10_same_std[0], null_samples_0v10_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(null_samples_0v100_same_std[0], null_samples_0v100_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(null_samples_0v1000_same_std[0], null_samples_0v1000_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "# Permuted sample comparisons\n",
    "for sample1, sample2 in zip(permuted_samples_0v10[0], permuted_samples_0v10[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(permuted_samples_0v100[0], permuted_samples_0v100[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(permuted_samples_0v1000[0], permuted_samples_0v1000[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(permuted_samples_0v10_same_std[0], permuted_samples_0v10_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(permuted_samples_0v100_same_std[0], permuted_samples_0v100_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "for sample1, sample2 in zip(permuted_samples_0v1000_same_std[0], permuted_samples_0v1000_same_std[1]):\n",
    "    ttest_vals.append(ttest_ind(sample1, sample2).statistic)\n",
    "\n",
    "ttest_vals = np.array(ttest_vals)\n",
    "\n",
    "# GP tree: takes two arrays as input, returns a test staistic\n",
    "pset = gp.PrimitiveSetTyped('MAIN', [np.ndarray, np.ndarray], float)\n",
    "pset.renameArguments(ARG0='x1')\n",
    "pset.renameArguments(ARG1='x2')\n",
    "\n",
    "# Logical operators on the distance array\n",
    "#pset.addPrimitive(np.logical_and, [np.ndarray, np.ndarray], np.ndarray, name='array_and')\n",
    "#pset.addPrimitive(np.logical_or, [np.ndarray, np.ndarray], np.ndarray, name='array_or')\n",
    "#pset.addPrimitive(np.logical_xor, [np.ndarray, np.ndarray], np.ndarray, name='array_xor')\n",
    "#pset.addPrimitive(np.logical_not, [np.ndarray], np.ndarray, name='array_not')\n",
    "\n",
    "# Mathematical operators on the distance array\n",
    "#pset.addPrimitive(np.add, [np.ndarray, np.ndarray], np.ndarray, name='array_add')\n",
    "#pset.addPrimitive(np.subtract, [np.ndarray, np.ndarray], np.ndarray, name='array_sub')\n",
    "#pset.addPrimitive(np.multiply, [np.ndarray, np.ndarray], np.ndarray, name='array_mul')\n",
    "#pset.addPrimitive(np.divide, [np.ndarray, np.ndarray], np.ndarray, name='array_div')\n",
    "pset.addPrimitive(np.sqrt, [np.ndarray], np.ndarray, name='array_sqrt')\n",
    "pset.addPrimitive(np.square, [np.ndarray], np.ndarray, name='array_square')\n",
    "pset.addPrimitive(np.abs, [np.ndarray], np.ndarray, name='array_abs')\n",
    "\n",
    "# Statistics derived from the distance array\n",
    "pset.addPrimitive(np.mean, [np.ndarray], float, name='array_mean')\n",
    "pset.addPrimitive(np.median, [np.ndarray], float, name='array_median')\n",
    "pset.addPrimitive(np.min, [np.ndarray], float, name='array_min')\n",
    "pset.addPrimitive(np.max, [np.ndarray], float, name='array_max')\n",
    "pset.addPrimitive(np.std, [np.ndarray], float, name='array_std')\n",
    "pset.addPrimitive(np.var, [np.ndarray], float, name='array_var')\n",
    "pset.addPrimitive(np.size, [np.ndarray], float, name='array_size')\n",
    "pset.addPrimitive(np.sum, [np.ndarray], float, name='array_sum')\n",
    "pset.addPrimitive(scipy.stats.sem, [np.ndarray], float, name='array_stderr')\n",
    "\n",
    "# Mathematical operators with single values\n",
    "def protected_div(left, right):\n",
    "    try:\n",
    "        return float(left) / float(right)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.\n",
    "\n",
    "pset.addPrimitive(operator.add, [float, float], float, name='float_add')\n",
    "pset.addPrimitive(operator.sub, [float, float], float, name='float_sub')\n",
    "pset.addPrimitive(operator.mul, [float, float], float, name='float_mul')\n",
    "pset.addPrimitive(protected_div, [float, float], float, name='float_div')\n",
    "pset.addPrimitive(np.sqrt, [float], float, name='float_sqrt')\n",
    "pset.addPrimitive(np.square, [float], float, name='float_square')\n",
    "pset.addPrimitive(np.abs, [float], float, name='float_abs')\n",
    "\n",
    "# Mathematical operators on the distance array with a single value\n",
    "pset.addPrimitive(np.add, [np.ndarray, float], np.ndarray, name='array_add_float')\n",
    "pset.addPrimitive(np.subtract, [np.ndarray, float], np.ndarray, name='array_sub_float')\n",
    "pset.addPrimitive(np.multiply, [np.ndarray, float], np.ndarray, name='array_mul_float')\n",
    "pset.addPrimitive(np.divide, [np.ndarray, float], np.ndarray, name='array_div_float')\n",
    "\n",
    "# Equivalence operators on the distance array with a single value\n",
    "#pset.addPrimitive(np.less, [np.ndarray, float], np.ndarray, name='array_less_than_float')\n",
    "#pset.addPrimitive(np.equal, [np.ndarray, float], np.ndarray, name='array_equal_float')\n",
    "\n",
    "# Terminals\n",
    "pset.addTerminal(1.0, float)\n",
    "#pset.addEphemeralConstant('rand{}'.format(np.random.randint(1e9)), lambda: np.random.random() * 100., float)\n",
    "#pset.addTerminal(np.multiply(np.random.random(size=features.shape[0]), 100.), np.ndarray)\n",
    "#pset.addTerminal(np.array([True] * features.shape[0]), np.ndarray)\n",
    "#pset.addTerminal(np.array([False] * features.shape[0]), np.ndarray)\n",
    "\n",
    "creator.create('FitnessMulti', base.Fitness, weights=tuple([-1.] * (num_splits + 1)))\n",
    "#creator.create('FitnessMulti', base.Fitness, weights=tuple([-1.] * (ttest_vals.shape[0] * 2)))\n",
    "creator.create('Individual', gp.PrimitiveTree, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('expr', gp.genHalfAndHalf, pset=pset, min_=1, max_=4)\n",
    "\n",
    "\"\"\"\n",
    "def return_ttest():\n",
    "    return creator.Individual.from_string('float_div(float_sub(array_mean(x1), array_mean(x2)), float_add(array_stderr(x1), array_stderr(x2)))', pset)\n",
    "    #return creator.Individual.from_string('float_div(float_sub(array_mean(x1), array_mean(x2)), float_sqrt(float_add(float_div(array_var(x1), array_size(x1)), float_div(array_var(x2), array_size(x2)))))', pset)\n",
    "\n",
    "toolbox.register('individual', return_ttest)\n",
    "\"\"\"\n",
    "toolbox.register('individual', tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register('compile', gp.compile, pset=pset)\n",
    "\n",
    "#pool = multiprocessing.Pool()\n",
    "#toolbox.register('map', pool.map)\n",
    "\n",
    "def evaluate_individual(individual):\n",
    "    # If the solution contains a constant value in it, throw it out\n",
    "    str_ind = str(individual)\n",
    "    if '1.0' in str_ind:\n",
    "        #return tuple([sys.maxsize] * (ttest_vals.shape[0] * 2))\n",
    "        return tuple([sys.maxsize] * (num_splits + 1))\n",
    "    \n",
    "    try:\n",
    "        func = toolbox.compile(expr=individual)\n",
    "    except:\n",
    "        #return tuple([sys.maxsize] * (ttest_vals.shape[0] * 2))\n",
    "        return tuple([sys.maxsize] * (num_splits + 1))\n",
    "\n",
    "    gp_ttest_vals = []\n",
    "    \n",
    "    # Sig diff sample comparisons\n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v10, sig_diff_samples_10v0):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "\n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v100, sig_diff_samples_100v0):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "\n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v1000, sig_diff_samples_1000v0):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "    \n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v10_same_std, sig_diff_samples_10v0_same_std):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "\n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v100_same_std, sig_diff_samples_100v0_same_std):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "\n",
    "    for sample1, sample2 in zip(sig_diff_samples_0v1000_same_std, sig_diff_samples_1000v0_same_std):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        gp_ttest_vals.append(func(sample2, sample1))\n",
    "\n",
    "    # Null sample comparisons\n",
    "    for sample1, sample2 in zip(null_samples_0v10[0], null_samples_0v10[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(null_samples_0v100[0], null_samples_0v100[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(null_samples_0v1000[0], null_samples_0v1000[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "\n",
    "    for sample1, sample2 in zip(null_samples_0v10_same_std[0], null_samples_0v10_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "\n",
    "    for sample1, sample2 in zip(null_samples_0v100_same_std[0], null_samples_0v100_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(null_samples_0v1000_same_std[0], null_samples_0v1000_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "    \n",
    "    # Permuted sample comparisons\n",
    "    for sample1, sample2 in zip(permuted_samples_0v10[0], permuted_samples_0v10[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(permuted_samples_0v100[0], permuted_samples_0v100[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(permuted_samples_0v1000[0], permuted_samples_0v1000[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "    \n",
    "    for sample1, sample2 in zip(permuted_samples_0v10_same_std[0], permuted_samples_0v10_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "    \n",
    "    for sample1, sample2 in zip(permuted_samples_0v100_same_std[0], permuted_samples_0v100_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    for sample1, sample2 in zip(permuted_samples_0v1000_same_std[0], permuted_samples_0v1000_same_std[1]):\n",
    "        gp_ttest_vals.append(func(sample1, sample2))\n",
    "        \n",
    "    gp_ttest_vals = np.array(gp_ttest_vals)\n",
    "\n",
    "    # If the solution produces NaN or inf values, throw it out\n",
    "    if np.any(np.isnan(gp_ttest_vals)) or np.any(np.isinf(gp_ttest_vals)):\n",
    "        #return tuple([sys.maxsize] * (ttest_vals.shape[0] * 2))\n",
    "        return tuple([sys.maxsize] * (num_splits + 1))\n",
    "\n",
    "    # Third fitness component is the size (i.e., complexity) of the GP tree\n",
    "    ind_complexity = np.sum([type(component) == gp.Primitive for component in individual])\n",
    "    abs_diffs = np.abs(np.subtract(gp_ttest_vals, ttest_vals))\n",
    "    \n",
    "    return tuple([np.sum(abs_diffs[i::num_splits]) for i in range(num_splits)] + [ind_complexity])\n",
    "    #return tuple(np.append(np.abs(np.subtract(gp_ttest_vals, ttest_vals)), [ind_complexity] * ttest_vals.shape[0]))\n",
    "\n",
    "toolbox.register('evaluate', evaluate_individual)\n",
    "toolbox.register('select', selAutomaticEpsilonLexicase)\n",
    "toolbox.register('mate', gp.cxOnePoint)\n",
    "toolbox.register('expr_mut', gp.genFull, min_=0, max_=3)\n",
    "toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "pop = toolbox.population(n=500)\n",
    "#stats = tools.Statistics(lambda ind: np.sum(ind.fitness.values[:ttest_vals.shape[0]]))\n",
    "stats = tools.Statistics(lambda ind: np.sum(ind.fitness.values[:-1]))\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "#t_test = creator.Individual.from_string('float_div(float_sub(array_mean(x1), array_mean(x2)), float_sqrt(float_add(float_div(array_var(x1), array_size(x1)), float_div(array_var(x2), array_size(x2)))))', pset)\n",
    "#print('t-test fitness: {}'.format(evaluate_individual(t_test)))\n",
    "\n",
    "#t_test = creator.Individual.from_string('float_div(float_sub(array_mean(x1), array_mean(x2)), float_add(array_stderr(x1), array_stderr(x2)))', pset)\n",
    "#print('t-test fitness: {}'.format(evaluate_individual(t_test)))\n",
    "\n",
    "pop, stats = algorithms.eaMuPlusLambda(population=pop, toolbox=toolbox,\n",
    "                                       cxpb=0.5, mutpb=0.5, mu=500, lambda_=500,\n",
    "                                       ngen=50, stats=stats)\n",
    "print('')\n",
    "\n",
    "pop_fitness = [(np.sum(ind.fitness.values[:-1]), ind.fitness.values[-1], str(ind)) for ind in pop]\n",
    "\n",
    "for (fitness, size, ind) in list(sorted(pop_fitness))[:10]:\n",
    "    print(fitness, size, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
